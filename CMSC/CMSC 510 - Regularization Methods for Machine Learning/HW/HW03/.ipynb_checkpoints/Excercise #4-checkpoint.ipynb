{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4932ad1",
   "metadata": {},
   "source": [
    "import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64ba4ee1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\echo4\\.conda\\envs\\pt\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import regularizers\n",
    "from keras.datasets import mnist\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7483ab80",
   "metadata": {},
   "source": [
    "Excercise #4: \n",
    "\n",
    "Larger Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ca0e35",
   "metadata": {},
   "source": [
    "Now to create our tensor of training and testing variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c68662f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_loss_fn(y_true, y_pred):\n",
    "    loss = tf.math.log(tf.add(1.0,tf.math.exp(tf.math.multiply(tf.math.multiply(-1.0,y_true),y_pred))))\n",
    "    return tf.reduce_mean(loss, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34bc8e93",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 4 6 6 4 4 6 6 6 4]\n",
      "tf.Tensor([-1. -1.  1.  1. -1. -1.  1.  1.  1. -1.], shape=(10,), dtype=float64)\n",
      "Epoch 1/5\n",
      "735/735 [==============================] - 3s 3ms/step - loss: 0.4829 - accuracy: 0.3628\n",
      "Epoch 2/5\n",
      "735/735 [==============================] - 2s 3ms/step - loss: 0.2226 - accuracy: 0.4730\n",
      "Epoch 3/5\n",
      "735/735 [==============================] - 2s 3ms/step - loss: 0.1429 - accuracy: 0.4849\n",
      "Epoch 4/5\n",
      "735/735 [==============================] - 2s 3ms/step - loss: 0.1066 - accuracy: 0.4883\n",
      "Epoch 5/5\n",
      "735/735 [==============================] - 2s 3ms/step - loss: 0.0864 - accuracy: 0.4906\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17f082af400>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load Dataset\n",
    "mnist = keras.datasets.mnist\n",
    "\n",
    "(x_train_raw, y_train_raw),(x_test_raw, y_test_raw) = mnist.load_data()\n",
    "\n",
    "# V = V00836246, therefore our classes are 4 and 6 \n",
    "\n",
    "# Note that this block of code grabs all of the 28x28 images which are either a 4 or a 6, and discards the rest.\n",
    "x_train_new, y_train_new = x_train_raw[(y_train_raw==4) | (y_train_raw==6)], y_train_raw[(y_train_raw==4) | (y_train_raw==6)]\n",
    "x_train_final = x_train_new.reshape((-1, 784))\n",
    "# Here we print the first ten datapoints to ensure our dataset is properly pruned.\n",
    "print(y_train_new[0:10])\n",
    "\n",
    "# Here we apply the same procedure to the testing data.\n",
    "x_test_new, y_test_new = x_test_raw[(y_test_raw==4) | (y_test_raw==6)], y_test_raw[(y_test_raw==4) | (y_test_raw==6)]\n",
    "x_test_final = x_test_new.reshape((-1, 784))\n",
    "\n",
    "# One last bit of data preprocessing. First we normalize the pixels of the x data:\n",
    "\n",
    "x_train_norm = x_train_final / 255\n",
    "x_test_norm = x_test_final / 255\n",
    "\n",
    "# Next I want to transform the y training from 4s and 6s into boolean true and false statements. 4 being false, and\n",
    "# 6 being true. This distinction is arbitrary.\n",
    "y_train_final = np.zeros(y_train_new.shape[0])\n",
    "y_test_final = np.zeros(y_test_new.shape[0])\n",
    "threshold = 5\n",
    "for i in range(y_train_new.shape[0]):\n",
    "        if y_train_new[i]>threshold:\n",
    "            y_train_final[i] = 1\n",
    "        else:\n",
    "            y_train_final[i] = -1\n",
    "for i in range(y_test_new.shape[0]):\n",
    "        if y_test_new[i]>threshold:\n",
    "            y_test_final[i] = 1\n",
    "        else:\n",
    "            y_test_final[i] = -1\n",
    "    \n",
    "y_train_final = tf.convert_to_tensor(y_train_final,dtype='float64')\n",
    "y_test_final = tf.convert_to_tensor(y_test_final,dtype='float64')\n",
    "print(y_train_final[0:10])\n",
    "\n",
    "\n",
    "\n",
    "model = keras.Sequential(\n",
    "  tf.keras.layers.Dense(1, input_shape=(784,), activation='linear', kernel_regularizer=regularizers.l2(l2=0.001))\n",
    ")\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "              loss=logistic_loss_fn, metrics=[tf.keras.metrics.Accuracy()])\n",
    "\n",
    "model.fit(\n",
    "  x=x_train_norm,\n",
    "  y=y_train_final,\n",
    "  shuffle=True,\n",
    "  epochs=5,\n",
    "  batch_size=16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae1085e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9247a10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 4 6 6 4 4 6 6 6 4]\n",
      "tf.Tensor([False False  True  True False False  True  True  True False], shape=(10,), dtype=bool)\n",
      "Epoch 1/5\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.1087 - binary_accuracy: 0.9749\n",
      "Epoch 2/5\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.0651 - binary_accuracy: 0.9894\n",
      "Epoch 3/5\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.0707 - binary_accuracy: 0.9889\n",
      "Epoch 4/5\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.0542 - binary_accuracy: 0.9911\n",
      "Epoch 5/5\n",
      "735/735 [==============================] - 1s 1ms/step - loss: 0.0523 - binary_accuracy: 0.9912\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1adcac381c0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Cheater Version\n",
    "mnist = keras.datasets.mnist\n",
    "\n",
    "(x_train_raw, y_train_raw),(x_test_raw, y_test_raw) = mnist.load_data()\n",
    "\n",
    "# V = V00836246, therefore our classes are 4 and 6 \n",
    "\n",
    "# Note that this block of code grabs all of the 28x28 images which are either a 4 or a 6, and discards the rest.\n",
    "x_train_new, y_train_new = x_train_raw[(y_train_raw==4) | (y_train_raw==6)], y_train_raw[(y_train_raw==4) | (y_train_raw==6)]\n",
    "x_train_final = x_train_new.reshape((-1, 784))\n",
    "# Here we print the first ten datapoints to ensure our dataset is properly pruned.\n",
    "print(y_train_new[0:10])\n",
    "\n",
    "# Here we apply the same procedure to the testing data.\n",
    "x_test_new, y_test_new = x_test_raw[(y_test_raw==4) | (y_test_raw==6)], y_test_raw[(y_test_raw==4) | (y_test_raw==6)]\n",
    "x_test_final = x_test_new.reshape((-1, 784))\n",
    "\n",
    "# One last bit of data preprocessing. First we normalize the pixels of the x data:\n",
    "\n",
    "x_train_norm = x_train_final / 255\n",
    "x_test_norm = x_test_final / 255\n",
    "\n",
    "# Next I want to transform the y training from 4s and 6s into boolean true and false statements. 4 being false, and\n",
    "# 6 being true. This distinction is arbitrary.\n",
    "y_train_final = np.zeros(y_train_new.shape[0])\n",
    "y_test_final = np.zeros(y_test_new.shape[0])\n",
    "threshold = 5\n",
    "for i in range(y_train_new.shape[0]):\n",
    "        if y_train_new[i]>threshold:\n",
    "            y_train_final[i] = True\n",
    "        else:\n",
    "            y_train_final[i] = False\n",
    "for i in range(y_test_new.shape[0]):\n",
    "        if y_test_new[i]>threshold:\n",
    "            y_test_final[i] = True\n",
    "        else:\n",
    "            y_test_final[i] = False\n",
    "    \n",
    "y_train_final = tf.convert_to_tensor(y_train_final,dtype='bool')\n",
    "y_test_final = tf.convert_to_tensor(y_test_final,dtype='bool')\n",
    "print(y_train_final[0:10])\n",
    "\n",
    "\n",
    "\n",
    "model = keras.Sequential(\n",
    "  tf.keras.layers.Dense(1, input_shape=(784,), activation='linear', kernel_regularizer=regularizers.l2(0.01))\n",
    ")\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['binary_accuracy'])\n",
    "\n",
    "model.fit(\n",
    "  x=x_train_norm,\n",
    "  y=y_train_final,\n",
    "  shuffle=True,\n",
    "  epochs=5,\n",
    "  batch_size=16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c860ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage{amssymb,amsmath,amsthm}

\title{STAT-513 Homework 2}
\author{John Hiles}
\date\today
%This information doesn't actually show up on your document unless you use the maketitle command below

\begin{document}
\maketitle %This command prints the title based on information entered above


\section*{Problem 1}
Suppose that a fair $n$-sided die is rolled $n$ times. A match occurs if the side $i$ is observed on the $i$th trial, $i=1,2,...$
\begin{enumerate}
\item
Show that the probability of at least one match is $1-(\frac{n-1}{n})^n = 1-(1-\frac{1}{n})^n$
\item
Find the limit of this probability as n approaches infinity.
\end{enumerate}

\subsection*{Part 1}
The best way to approach this problem is to count the possible outcomes. 

\clearpage

\section*{Problem 2}
From an ordinary deck of playing cards, cards are to be drawn successively, at random and without replacement. Find the probability that the third ace appears in the sixth draw.
%EVENT B = two aces are drawn in the first five draws
\subsection*{Part 1}
We need to break this event down to calculate the probability.
Let event $A$ be the event in which the third ace appears on the sixth draw.
For event $A$ to occur, another event which we shall call $B$ must occur first: in the first five draws, two of the five cards must be aces.
\clearpage
\section*{Problem 3}
Bean seeds from supplier A have an 85\% germination rate and those from supplier B have a 75\% germination rate. A seed packaging company purchases 40\% of their bean seeds from supplier A and 60\% from supplier B and mixes these seeds together.
\begin{enumerate}
%Weighted average, 40 and 60 percent are weights to apply to the given rates.
%If you don't know it germinated probability is from A is 40%, but B shifts it towards A.


\item
Find the probability $P(G)$ that a seed selected at random from the mixed seeds will germinate.
\item
Given that a seed germinates, find the probability that the seed was purchased from supplier A.
\end{enumerate}
\subsection*{Part 1}
\clearpage
\section*{Problem 4}
Prove each of the following statements. (Assume that any conditioning event has positive probability.)
\begin{enumerate}
\item
If $P(B) = 1$, then $P(A|B) = P(A)$ for any $A$
\item
If $A \subset B$, then $P(B|A) = 1$ and $P(A|B)=P(A)/P(B)$
\item
%Given B, what is the probability that an event inside smaller subset A occurs
If $A$ and $B$ are mutually exclusive then $P(A|A\cup B) = \dfrac{P(A)}{P(A)+P(B)}$
\item
$P(A\cap B \cap C) = P(A|B\cup C) P(B|C) P(C)$
\end{enumerate}
\subsection*{Part 1}
The definition of conditional probability is given by:
\begin{align*}
P(A|B) = \dfrac{P(A\cap B}{P(B)}
\end{align*}
The probability of the complement of $B$ is:
\begin{align*}
P(B^C) = 1-P(B) = 1-1 = 0
\end{align*}
We can rewrite P(A) as:
\begin{align*}
P(A) = P(A\cap B) + P(A\cap B^C)
\end{align*}
Since $P(B) = 1$, $P(B^C)=0$. Furthermore, $A\cap B^C\subset B^C$ therefore $P(A\cap B^C)$ must equal zero:
\begin{align*}
P(A\cap B^C) = 0
\end{align*}
Thus
\begin{align*}
P(A) = P(A\cap B)
\end{align*}
\begin{align*}
P(A|B) = \dfrac{P(A)}{P(B)}
\end{align*}
Note that $P(B)=1$ so we are left with:
\begin{align*}
\boxed{P(A|B) = \dfrac{P(A)}{P(B)}}
\end{align*}
\subsection*{Part 2}
The first part is fairly easy to prove. The definition of conditional probability is given by:
\begin{align*}
P(B|A) = \dfrac{P(B\cap A)}{P(A)}
\end{align*}
Since $A \subset B$, we know that the intersection of $A$ and $B$ are simply the set A.
\begin{align*}
A\cap B = A
\end{align*}
Thus
\begin{align*}
P(A\cap B) = P(A)
\end{align*}
Consequently, our conditional probability of $P(B|A)$ reduces to:
\begin{align*}
\boxed{P(B|A) = \dfrac{P(A)}{P(A)} = 1}
\end{align*}
The second part then reduces to:
\begin{align*}
\boxed{P(A|B) = \dfrac{P(A\cap B}{P(B)}=\dfrac{P(A)}{P(B)}}
\end{align*}
This makes intuitive sense, B being a larger set, the conditional probability would depend on the relative sizes of sets $A$ and $B$.
\subsection*{Part 3}
The definition of conditional probability is given by:
\begin{align*}
P(A|A\cup B) = \dfrac{P((A\cup B)\cap A)}{P(A\cup B)}
\end{align*}
The distributive law can be applied to the numerator:
\begin{align*}
P((A\cup B)\cap A) = (A\cap A)\cup (A\cap B)
\end{align*}
Mutual exclusivity of $A$ and $B$ means:
\begin{align*}
A\cap B = \emptyset \text{ and } P(A\cap B) = 0
\end{align*}
With this, we can simplify 
\begin{align*}
(A\cap A)\cup (A\cap B) = A \cup \emptyset
\end{align*}
\begin{align*}
(A\cap A)\cup (A\cap B) = A
\end{align*}
Thus our original conditional probability expression reduces to:
\begin{align*}
P(A|A\cup B) = \dfrac{P(A)}{P(A\cup B)}
\end{align*}
Furthermore, being mutually exclusive events, their union can be treated as a sum.
\begin{align*}
P(A\cup B) = P(A) + P(B)
\end{align*}
\begin{align*}
\boxed{P(A|A\cup B) = \dfrac{P(A)}{P(A) + P(B)}}
\end{align*}

\subsection*{Part 4}
Prove $P(A\cap B \cap C) = P(A|B\cup C) P(B|C) P(C)$

We can start by rewriting the conditional events in terms of sets and their intersections.
The following identity is very useful in this problem:
\begin{align*}
P(A\cap B) = P(A|B)P(B)
\end{align*}
This can be used for the rightmost factors:
\begin{align*}
P(A|B\cup C) P(B|C) P(C) = P(A|B\cup C) P(B\cap C)
\end{align*}
This identity can be applied again, treating $B\cup C$ as an event.
\begin{align*}
\boxed{P(A\cap B) = P(A|B)P(B) = P(A\cap B \cap C)}
\end{align*}
\clearpage

\section*{Problem 5}
An urn contains $a$ white balls and $b$ black balls. Another urn contains $c$ white balls and $d$ black balls. One ball is drawn at random from the first urn and transferred to the second urn without noting down its color. One ball is now drawn at random from the second urn.

\begin{enumerate}
    \item
    Find the probability that the ball drawn is white.
    \item
    Suppose the ball drawn from the second urn is found to be white. What is the probability that the ball transferred from the first urn was white?
    \end{enumerate}
\subsection*{Part 1}
Lets first specify the probabilities of some basic events, before the ball swap, the probability of drawing white or black balls from the first urn is:
\begin{align*}
P(W_1) = \frac{a}{a+b} \text{ and } P(B_1) = \frac{b}{a+b}
\end{align*}
The probabilities for the second urn are predictably:
\begin{align*}
P(W_2) = \frac{c}{c+d} \text{ and } P(B_2) = \frac{d}{c+d} = 1-P(W_2)
\end{align*}
For the transfer, there are two possible outcomes. A white ball is taken from the first urn and put in the second, or a black ball is put in the second urn. Lets analyze the probabilities in these cases.
Let $W^W$ and $W^B$ denote the event where white and black balls are added respectively. 
\begin{align*}
P(W^W) = \frac{c+1}{c+d+1} \text{ and } P(W^B) = \frac{c}{c+d+1}
\end{align*}
The trick here is that the likelihood of the ball picked to be white is not equally likely as a black ball being picked. It is dependent on the probability of a random draw from the first urn. We can then quantify the probability of drawing white as a weighted average of these two probability functions, weighted according to the probabilities drawing from the first urn.
\begin{align*}
P(W) = P(W_1)\frac{c+1}{c+d+1} + 1-P(W_1) P(W^B) \frac{c}{c+d+1}
\end{align*}
\begin{align*}
\boxed{P(W) = \frac{a}{a+b}  \frac{c+1}{c+d+1} + \frac{b}{a+b} \frac{c}{c+d+1}}
\end{align*}

\subsection*{Part 2}
For this, we can use our result from part 1 as a given event for our conditional probability expression.
Let $P(B)=P(W)$
\begin{align*}
P(B) = \frac{a}{a+b}  \frac{c+1}{c+d+1} + \frac{b}{a+b} \frac{c}{c+d+1}}
\end{align*}
The definition of conditional probability is then given by:
\begin{align*}
P(A|B) = \dfrac{P(A\cap B}{P(B)}
\end{align*}



\clearpage
\section*{Problem 6}
In a game of 5 card stud, where you draw 5 cards out of 52(assume no other players are involved), calculate the probability of getting three of a kind.
\subsection*{Part 1}

\clearpage
\section*{Problem 7}
Let $X,Y,Z$ be a partition of the sample space S and P be a probability function.

    \begin{enumerate}
    \item
    Show that any event $A\subseteq \mathcal{S}$ has probability: $P(A) = P(A|X)P(X)+P(Y|A)P(A)+P(A|Z)P(Z)$
    \item
    Is it always true that: $P(A) = \dfrac{P(A|X)P(X)+P(A|Z)P(Z)}{1-P(Y|A)}$
    \end{enumerate}
\subsection*{Part 1}



\end{document}
\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage{amssymb,amsmath,amsthm}

\title{STAT-513 Homework 2}
\author{John Hiles}
\date\today
%This information doesn't actually show up on your document unless you use the maketitle command below

\begin{document}
\maketitle %This command prints the title based on information entered above


\section*{Problem 1}
Suppose that a fair $n$-sided die is rolled $n$ times. A match occurs if the side $i$ is observed on the $i$th trial, $i=1,2,...$
\begin{enumerate}
\item
Show that the probability of at least one match is $1-(\frac{n-1}{n})^n = 1-(1-\frac{1}{n})^n$
\item
Find the limit of this probability as n approaches infinity.
\end{enumerate}

\subsection*{Part 1}
The best way to approach this problem is to count the possible outcomes. 

Let each roll of the $n$ sided dice be represented by $i$. The $i$th roll leads to $n^i$ outcomes.
Also let $A$ be the event in which a match is observed on the $i$th roll. Then

\begin{align*}
P(A) = 1-P(A^C)
\end{align*}
The likelihood that a match does not occur is actually much easier to express than the likleyhood that a match does occur. Each roll, only one number will yield a match.
\begin{align*}
P(A^C) = (\dfrac{n-1}{n})^n
\end{align*}
As such, $P(A)$ can be expressed as:
\begin{align*}
\boxed{P(A) = 1-(\frac{n-1}{n})^n}
\end{align*}

\subsection*{Part 2}
$\boxed{\text{As }n\to\infty, P(A)\text{ approaches }0.}$

\clearpage

\section*{Problem 2}
From an ordinary deck of playing cards, cards are to be drawn successively, at random and without replacement. Find the probability that the third ace appears in the sixth draw.
%EVENT B = two aces are drawn in the first five draws
\subsection*{Part 1}
We need to break this event down to calculate the probability.
Let event $A$ be the event in which the third ace appears on the sixth draw.
For event $A$ to occur, another event which we shall call $B$ must occur first: in the first five draws, two of the five cards must be aces.

First lets figure out the total number of draws possible for event $B$. There are 52 cards in a deck. We are drawing 5 cards without replacement, therefore our total number of possible five card draws is:
\begin{align*}
\begin{bmatrix}
52 \\
5
\end{bmatrix}
\end{align*}
To count the number of hands which satisfy the conditions specified here (2 cards) 
\begin{align*}
(1)
\begin{bmatrix}
4 \\
3
\end{bmatrix}
\begin{bmatrix}
12 \\
3
\end{bmatrix}
(4^3)
\end{align*}
Note that this example is the same as the formulation from the textbook $P(exactly one pair)$, the only difference is a factor of 13, because we are interested in a pair of aces specifically as opposed to a pair of any kind of card. As such, the probabality of getting a pair of aces in the first draw is:
\begin{align*}
P(A) = \dfrac{
\begin{bmatrix}
4 \\
3
\end{bmatrix}
\begin{bmatrix}
12 \\
3
\end{bmatrix}
(4^3)}
{\begin{bmatrix}
52 \\
5
\end{bmatrix}} = 0.02167
\end{align*}

Now, the event we want is event where we draw an ace AFTER event $B$ just occurred.

The probability of drawing an ace now from a deck in which 5 cards were drawn, and two of those were aces is $\frac{2}{47}$. So our final probability of the odds of drawing the third ace on the sixth draw is

\begin{align*}
\boxed{\frac{2}{47} P(B) = 0.000922}
\end{align*}
\clearpage
\section*{Problem 3}
Bean seeds from supplier A have an 85\% germination rate and those from supplier B have a 75\% germination rate. A seed packaging company purchases 40\% of their bean seeds from supplier A and 60\% from supplier B and mixes these seeds together.
\begin{enumerate}
%Weighted average, 40 and 60 percent are weights to apply to the given rates.
%If you don't know it germinated probability is from A is 40%, but B shifts it towards A.


\item
Find the probability $P(G)$ that a seed selected at random from the mixed seeds will germinate.
\item
Given that a seed germinates, find the probability that the seed was purchased from supplier A.
\end{enumerate}
\subsection*{Part 1}
Find the probability $P(G)$ that a seed selected at random from the mixed seeds will germinate.

The germination rate for the seed mixture is a weighted average of the two seed suppliers.
\begin{align*}
\boxed{P(G) = (0.40)(0.85) + (0.60)(.75) = 0.79}
\end{align*}
\subsection*{Part 2}
Let $A$ be the event that the seed belonged to vendor A.
The definition of conditional probability is given by:
\begin{align*}
P(A|G) = \dfrac{P(A\cap G)}{P(G)}
\end{align*}
This can be rewritten as:
\begin{align*}
P(A|G) = P(G|A)\dfrac{P(A)}{P(G)}
\end{align*}
In this case, $P(G|A)$ refers to the probability of a seed germinating if it came from vendor $A$, which is known to us. 
\begin{align*}
P(G|A) = (0.85)
\end{align*}
As such:
\begin{align*}
\boxed{P(A|G) = (0.85)\dfrac{(0.4)}{(0.79)}}
\end{align*}
As such, there is a $\boxed{0.43}$ chance that our seed came from vendor A.

\clearpage
\section*{Problem 4}
Prove each of the following statements. (Assume that any conditioning event has positive probability.)
\begin{enumerate}
\item
If $P(B) = 1$, then $P(A|B) = P(A)$ for any $A$
\item
If $A \subset B$, then $P(B|A) = 1$ and $P(A|B)=P(A)/P(B)$
\item
%Given B, what is the probability that an event inside smaller subset A occurs
If $A$ and $B$ are mutually exclusive then $P(A|A\cup B) = \dfrac{P(A)}{P(A)+P(B)}$
\item
$P(A\cap B \cap C) = P(A|B\cup C) P(B|C) P(C)$
\end{enumerate}
\subsection*{Part 1}
The definition of conditional probability is given by:
\begin{align*}
P(A|B) = \dfrac{P(A\cap B)}{P(B)}
\end{align*}
The probability of the complement of $B$ is:
\begin{align*}
P(B^C) = 1-P(B) = 1-1 = 0
\end{align*}
We can rewrite P(A) as:
\begin{align*}
P(A) = P(A\cap B) + P(A\cap B^C)
\end{align*}
Since $P(B) = 1$, $P(B^C)=0$. Furthermore, $A\cap B^C\subset B^C$ therefore $P(A\cap B^C)$ must equal zero:
\begin{align*}
P(A\cap B^C) = 0
\end{align*}
Thus
\begin{align*}
P(A) = P(A\cap B)
\end{align*}
\begin{align*}
P(A|B) = \dfrac{P(A)}{P(B)}
\end{align*}
Note that $P(B)=1$ so we are left with:
\begin{align*}
\boxed{P(A|B) = P(A)}
\end{align*}
\subsection*{Part 2}
The first part is fairly easy to prove. The definition of conditional probability is given by:
\begin{align*}
P(B|A) = \dfrac{P(B\cap A)}{P(A)}
\end{align*}
Since $A \subset B$, we know that the intersection of $A$ and $B$ are simply the set A.
\begin{align*}
A\cap B = A
\end{align*}
Thus
\begin{align*}
P(A\cap B) = P(A)
\end{align*}
Consequently, our conditional probability of $P(B|A)$ reduces to:
\begin{align*}
\boxed{P(B|A) = \dfrac{P(A)}{P(A)} = 1}
\end{align*}
The second part then reduces to:
\begin{align*}
\boxed{P(A|B) = \dfrac{P(A\cap B)}{P(B)}=\dfrac{P(A)}{P(B)}}
\end{align*}
This makes intuitive sense, B being a larger set, the conditional probability would depend on the relative sizes of sets $A$ and $B$.
\subsection*{Part 3}
The definition of conditional probability is given by:
\begin{align*}
P(A|A\cup B) = \dfrac{P((A\cup B)\cap A)}{P(A\cup B)}
\end{align*}
The distributive law can be applied to the numerator:
\begin{align*}
P((A\cup B)\cap A) = (A\cap A)\cup (A\cap B)
\end{align*}
Mutual exclusivity of $A$ and $B$ means:
\begin{align*}
A\cap B = \emptyset \text{ and } P(A\cap B) = 0
\end{align*}
With this, we can simplify 
\begin{align*}
(A\cap A)\cup (A\cap B) = A \cup \emptyset
\end{align*}
\begin{align*}
(A\cap A)\cup (A\cap B) = A
\end{align*}
Thus our original conditional probability expression reduces to:
\begin{align*}
P(A|A\cup B) = \dfrac{P(A)}{P(A\cup B)}
\end{align*}
Furthermore, being mutually exclusive events, their union can be treated as a sum.
\begin{align*}
P(A\cup B) = P(A) + P(B)
\end{align*}
\begin{align*}
\boxed{P(A|A\cup B) = \dfrac{P(A)}{P(A) + P(B)}}
\end{align*}

\subsection*{Part 4}
We can start by rewriting the sets in terms of conditional probability:
\begin{align*}
P(A\cap B\cap C) =  P(A\cap (B \cap C))
\end{align*}
\begin{align*}
= P(A|B\cap C) P(B\cap C)
\end{align*}
\begin{align*}
\boxed{= P(A|B\cap C) P(B|C)P(C)}
\end{align*}
\clearpage

\section*{Problem 5}
An urn contains $a$ white balls and $b$ black balls. Another urn contains $c$ white balls and $d$ black balls. One ball is drawn at random from the first urn and transferred to the second urn without noting down its color. One ball is now drawn at random from the second urn.

\begin{enumerate}
    \item
    Find the probability that the ball drawn is white.
    \item
    Suppose the ball drawn from the second urn is found to be white. What is the probability that the ball transferred from the first urn was white?
    \end{enumerate}
\subsection*{Part 1}
Lets first specify the probabilities of some basic events, before the ball swap, the probability of drawing white or black balls from the first urn is:
\begin{align*}
P(W_1) = \frac{a}{a+b} \text{ and } P(B_1) = \frac{b}{a+b}
\end{align*}
The probabilities for the second urn are predictably:
\begin{align*}
P(W_2) = \frac{c}{c+d} \text{ and } P(B_2) = \frac{d}{c+d} = 1-P(W_2)
\end{align*}
For the transfer, there are two possible outcomes. A white ball is taken from the first urn and put in the second, or a black ball is put in the second urn. Lets analyze the probabilities in these cases.
Let $W^W$ and $W^B$ denote the event where white and black balls are added respectively. 
\begin{align*}
P(W^W) = \frac{c+1}{c+d+1} \text{ and } P(W^B) = \frac{c}{c+d+1}
\end{align*}
The trick here is that the likelihood of the ball picked to be white is not equally likely as a black ball being picked. It is dependent on the probability of a random draw from the first urn. We can then quantify the probability of drawing white as a weighted average of these two probability functions, weighted according to the probabilities drawing from the first urn.
\begin{align*}
P(W) = P(W_1)\frac{c+1}{c+d+1} + 1-P(W_1) P(W^B) \frac{c}{c+d+1}
\end{align*}
\begin{align*}
\boxed{P(W) = \frac{a}{a+b}  \frac{c+1}{c+d+1} + \frac{b}{a+b} \frac{c}{c+d+1}}
\end{align*}

\subsection*{Part 2}
For this, we can use our result from part 1 as a given event for our conditional probability expression.
Let $A$ refer to the event in which the ball transferred from the first urn to the second is white. $W$ is the event in which the first ball drawn is white.
\begin{align*}
P(W) = \frac{a}{a+b}  \frac{c+1}{c+d+1} + \frac{b}{a+b} \frac{c}{c+d+1}
\end{align*}
The definition of conditional probability is then given by:
\begin{align*}
P(A|W) = \dfrac{P(A\cap W)}{P(W)}
\end{align*}
\begin{align*}
P(A|W) = P(W|A)\dfrac{P(A)}{P(W)}
\end{align*}
$P(W|A)$ in this case refers to the probability of white being drawn given that the ball transferred is white. We already have this expression in $P(W^W)$
\begin{align*}
P(A|W) = P(W^W) = \frac{c+1}{c+d+1}
\end{align*}
$P(A)$ is also known, and represents the probability of drawing white from the original container:
\begin{align*}
P(A) = P(W_1) = \frac{a}{a+b}
\end{align*}
Substituting in to our conditional probability equation yields:
\begin{align*}
P(A|W) = \dfrac{c+1}{c+d+1}\dfrac{\frac{a}{a+b}}{\frac{a}{a+b}  \frac{c+1}{c+d+1} + \frac{b}{a+b} \frac{c}{c+d+1}}
\end{align*}
This rather messy expression simplifies to:
\begin{align*}
\boxed{P(A|W) = \dfrac{a(c+1)}{a(c+1)+(b c)}}
\end{align*}

\clearpage
\section*{Problem 6}
In a game of 5 card stud, where you draw 5 cards out of 52(assume no other players are involved), calculate the probability of getting three of a kind.
\subsection*{Part 1}
The total number of 5 card draws is given by:
\begin{align*}
\begin{bmatrix}
52 \\
5
\end{bmatrix}
\end{align*}
For a hand of cards, there are 13 choices in number per card (10 numbers, 3 face cards), there are three choices out of four suits, three choices of suit for the remaining 12 numbers, and finally there are $4^2$ ways of specifying the other three cards from those denominations.
\begin{align*}
\boxed{P(\text{Three of a kind}) = 
\dfrac{(13)
\begin{bmatrix}
4 \\
3
\end{bmatrix}
\begin{bmatrix}
12 \\
2
\end{bmatrix}
(4^2)}
{\begin{bmatrix}
52 \\
5
\end{bmatrix}} = 0.021128}
\end{align*}


\clearpage
\section*{Problem 7}
Let $X,Y,Z$ be a partition of the sample space $\mathcal{S}$ and P be a probability function.
    \begin{enumerate}
    \item
    Show that any event $A\subseteq \mathcal{S}$ has probability: $P(A) = P(A|X)P(X)+P(Y|A)P(A)+P(A|Z)P(Z)$
    \item
    Is it always true that: $P(A) = \dfrac{P(A|X)P(X)+P(A|Z)P(Z)}{1-P(Y|A)}$
    \end{enumerate}
\subsection*{Part 1}

Via the definition of conditional probability, we can rewrite these additive terms in set notation.
\begin{align*}
P(A|X)P(X)+P(Y|A)P(A)+P(A|Z)P(Z) = P(A\cap X) + P(A\cap Y) + P(A\cap Z)
\end{align*}
In this notation, the result is much more intuitive. Given that $X,Y,Z$ completely cover $\mathcal{S}$, it makes sense that an the probability of an event $A$ occurring can be described by how many elements are common to $A$ and the partitions of $\mathcal{S}$.

It should be obvious that the sum of the intersections of the three partitions is equivalent to the intersection of $A$ and $\mathcal{S}$

\begin{align*}
P(A\cap X) + P(Y\cap A) + P(A\cap Z) = P(A\cap S)
\end{align*}
$A\subseteq \mathcal{S}$, therefore 
\begin{align*}
\boxed{P(A\cap S) = P(A)}
\end{align*}
\subsection*{Part 2}
Suppose $Y \subseteq A$
\begin{align*}
P(Y|A)= 1
\end{align*}
If $P(A|Y)= 1$, then the expression becomes:
\begin{align*}
P(A) = \dfrac{P(A|X)P(X)+P(A|Z)P(Z)}{0}
\end{align*}
Which is undefined. For P to be a valid probability function it must be greater than or equal to zero for all $A\in S$
\end{document}